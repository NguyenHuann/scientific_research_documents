# VII. LOẠI TRUY XUẤT

Nhiều **loại truy xuất (retrieval types)** khác nhau đã được khám phá bằng cách sử dụng các phương pháp tiếp cận học sâu, dựa trên **bản chất của bài toán (nature of the problem)** và **dữ liệu (data)**, như sẽ được thảo luận trong phần này.

## A. Truy xuất Đa phương thức (Cross-modal Retrieval)

**Truy xuất đa phương thức (Cross-modal retrieval)** đề cập đến việc truy xuất ảnh liên quan đến **nhiều hơn một phương thức (modality)** bằng cách đo lường độ tương tự giữa các **đối tượng dữ liệu không đồng nhất (heterogeneous data objects)**.

*   Feng et al. (2014) đã giới thiệu một mạng **mã tự động tương ứng (correspondence autoencoder - Corr-AE)** cho truy xuất đa phương thức [125].
*   Năm 2016 [201], một mạng **băm ngữ nghĩa-trực quan sâu (deep visual-semantic hashing - DVSH)** được phát triển cho truy xuất đa phương thức dựa trên **câu (sentence)** và **ảnh (image)** bằng cách đồng thời học các **phép nhúng (embeddings)** cho hình ảnh và câu.
*   Mô hình **binaries sâu văn bản-trực quan (Textual-visual deep binaries - TVDB)** biểu diễn các câu mô tả dài cùng với các hình ảnh thông tin tương ứng của nó [139].
*   Các đặc trưng trực quan CNN cũng đã được khai thác cho truy xuất đa phương thức, chẳng hạn như:
    *   Các đặc trưng CNN **dùng ngay (off-the-shelf)** cho **chú thích có nhãn (labelled annotation)** [134]
    *   Đặc trưng CNN với **mất mát bản lề hai chiều (bidirectional hinge loss)** [202]
    *   Mạng băm sâu dựa trên **các ràng buộc theo cặp (pairwise constraints)** [142]
*   Mạng neural **đối kháng (adversarial)** cũng được sử dụng cho truy xuất đa phương thức, chẳng hạn như:
    *   Truy xuất đa phương thức đối kháng (Adversarial cross-modal retrieval - ACMR) [143]
    *   Băm đối kháng tự giám sát (Self-supervised adversarial hashing - SSAH) [146]
    *   Băm đối kháng sâu nhận biết sự chú ý (Attention-aware deep adversarial hashing - ADAH) [145]
    *   Băm bất đối xứng được hướng dẫn bởi đối thủ (Adversary guided asymmetric hashing - AGAH) [160]
    *   Băm ngữ nghĩa đa cấp sâu (Deep multi-level semantic hashing - DMSH) [198]
    *   Học giáo viên-học sinh (Teacher-student learning) [203]
    ## B. Truy xuất Ảnh dựa trên Phác thảo (Sketch Based Image Retrieval - SBIR)

**Truy xuất ảnh dựa trên phác thảo (SBIR)** là một trường hợp đặc biệt của truy xuất đa phương thức, trong đó **ảnh truy vấn (query image)** nằm trong **miền phác thảo (sketch domain)** và việc truy xuất phải được thực hiện trong **miền ảnh (image domain)** [204].

*   Năm 2017, một phương pháp **SBIR chi tiết (fine-grained SBIR - FG-SBIR)** [137] được khám phá với sự trợ giúp của **mô-đun chú ý (attention module)** và **hàm mất mát năng lượng có thể học bậc cao (higher-order learnable energy function loss)**.
*   Liu et al. (2017) [205] đã giới thiệu một mô hình **băm phác thảo sâu bán không đồng nhất (semi-heterogeneous deep sketch hashing - DSH)** cho SBIR bằng cách sử dụng biểu diễn của các **bản phác thảo vẽ tay (free-hand sketches)**.
*   Các bản phác thảo và ảnh chụp tự nhiên được ánh xạ trong **nhiều lớp (multiple layers)** trong một framework CNN sâu trong [151] cho SBIR.
*   Một phương pháp **SBIR không nhìn thấy (zero-shot SBIR - ZS-SBIR)** được đề xuất để truy xuất ảnh từ các **danh mục chưa từng thấy (unseen categories)** [153].
*   Wang et al. (2019) [158] đã đề xuất một phương pháp **xếp hạng lại (re-ranking)** SBIR dựa trên CNN để **tinh chỉnh (refine)** kết quả truy xuất.
*   Các **mạng đối sinh (generative adversarial networks)** cũng đã được khai thác rộng rãi cho SBIR, chẳng hạn như:
    *   **Băm di chuyển miền sinh (Generative domain-migration hashing - GDH)** sử dụng **mất mát tính nhất quán chu kỳ (cycle consistency loss)** [148]
    *   **Mô hình sinh có điều kiện phác thảo lớp (Class sketch conditioned generative model)** [159]
    *   **Mô hình sinh nhất quán chu kỳ theo cặp được căn chỉnh ngữ nghĩa (Semantically aligned paired cycle-consistent generative model)** [206]
    *   **Mạng đối kháng xếp chồng (Stacked adversarial network)** [163]

## C. Truy xuất Ảnh Đa nhãn (Multi-label Image Retrieval)

**Truy xuất đa nhãn (Multi-label retrieval)** liên quan đến **nhiều nhãn danh mục (multiple categorical labels)** trong khi tạo ra các **biểu diễn hình ảnh (image representations)** cho truy xuất ảnh.

Một số phương pháp học sâu đã được nghiên cứu cho truy xuất ảnh đa nhãn bằng cách sử dụng các chiến lược khác nhau, chẳng hạn như:
*   **Thông tin tương tự đa cấp (Multilevel similarity information)** [207]
*   **Băm bảo toàn độ tương tự ngữ nghĩa đa cấp (Multilevel semantic similarity preserving hashing)** [208]
*   **Chú thích đa nhãn (Multi-label annotations)** [146]
*   **Băm dựa trên đối tượng nhận biết danh mục (Category-aware object based hashing)** [209], [210]
*   **Đặc trưng chi tiết (Fine-grained features)** cho băm độ tương tự đa cấp [211]

Độc giả có thể tham khảo bài **tổng quan về truy xuất ảnh đa nhãn** [43] được xuất bản năm 2020 để biết các khía cạnh và phát triển rộng hơn.

## D. Truy xuất Thể hiện (Instance Retrieval)

*   Năm 2015, Razavian et al. đã phát triển một **đường cơ sở (baseline)** cho **truy xuất thể hiện trực quan (visual instance retrieval)** dựa trên CNN sâu [212].
*   Một phương pháp **biểu diễn ảnh nhận biết thể hiện (instance-aware image representations)** cho dữ liệu ảnh đa nhãn bằng cách mô hình hóa các đặc trưng của một danh mục trong một nhóm được đề xuất trong [209].
*   Các phương pháp tiếp cận khác cho truy xuất thể hiện ảnh bao gồm:
    *   **Túi các đặc trưng tích chập cục bộ (Bags of local convolutional features)** [187]
    *   Học **biểu diễn toàn cục (global representations)** [65]
    *   **Biểu diễn sâu bất biến nhóm (Group invariant deep representation)** [213]
*   Năm 2020, Chen et al. đã đề xuất một mô hình **băm dựa trên xếp hạng đa thể hiện sâu (deep multiple-instance ranking based hashing - DMIRH)** cho truy xuất ảnh đa nhãn bằng cách sử dụng **túi đặc trưng nhận biết danh mục (category-aware bag of feature)** [210].
*   Chi tiết thêm về truy xuất thể hiện ảnh có thể được tìm thấy trong bài tổng quan được biên soạn trong [42].

## E. Truy xuất Đối tượng (Object Retrieval)

**Truy xuất đối tượng (Object retrieval)** nhằm mục đích thực hiện truy xuất dựa trên các đặc trưng có nguồn gốc từ các **đối tượng cụ thể (specific objects)** trong hình ảnh.

*   Năm 2014, Sun et al. đã trích xuất các đặc trưng CNN từ **vùng quan tâm (region of interest)** được phát hiện thông qua kỹ thuật **phát hiện đối tượng (object detection)** để truy xuất dựa trên đối tượng [126].
*   Một số mô hình học sâu đã được nghiên cứu cho truy xuất đối tượng, chẳng hạn như:
    *   **Gộp cực đại (Max-pooling)** được điều khiển bởi **ảnh tích phân (integral image)** trên các kích hoạt CNN [214]
    *   **Gộp (Pooling)** các đặc trưng liên quan dựa trên **mạng đề xuất vùng (region proposal network)** [65]
    *   **Lựa chọn và gán trọng số đồng thời (Simultaneous selection and weighting)** của các đặc trưng CNN sâu nguyên thủy dựa trên **phương trình replicator (replicator equation)** [215]
    *   **Tổng hợp dựa trên đồng trọng số (Co-weighting based aggregation)** của các đặc trưng CNN ngữ nghĩa [199]
    *   Xem xét **đóng góp của không gian và kênh (spatial and channel contribution)** để cải thiện việc phát hiện vùng [216]
*   Gao et al. (2020) [165] đã thực hiện **truy xuất đối tượng 3D (3D object retrieval)** với sự trợ giúp của một mạng **CNN đa chế độ xem phân biệt và theo cặp (multi-view discrimination and pairwise CNN - MDPCNN)**.

## F. Truy xuất Ngữ nghĩa (Semantic Retrieval)

*   Năm 2016, Yao et al. [131] đã giới thiệu một phương pháp **băm dựa trên bảo toàn ngữ nghĩa sâu và xếp hạng (deep semantic preserving and ranking-based hashing - DSRH)** bằng cách khai thác các **mất mát băm (hash)** và **mất mát phân loại (classification)**. Các mất mát tương tự cũng được sử dụng trong [217].
*   Một phương pháp **lượng tử hóa ngữ nghĩa-trực quan sâu (deep visual-semantic quantization - DVSQ)** [218] được sử dụng bằng cách đồng thời học các **phép nhúng ngữ nghĩa-trực quan (visual-semantic embeddings)** và **bộ lượng tử hóa (quantizers)**.
*   Một phương pháp **tổng hợp dựa trên bộ lọc Gaussian thích ứng (adaptive Gaussian filter based aggregation)** của các đặc trưng CNN được sử dụng trong [199] để khai thác thông tin ngữ nghĩa.
*   **Băm ngữ nghĩa (Semantic hashing)** cũng đã được thực hiện rộng rãi cho:
    *   Truy xuất ảnh dựa trên phác thảo [137], [153], [206], [158]
    *   Truy xuất đa phương thức [198], [201], [139]
*   Các công trình đáng chú ý khác dựa trên học sâu mô hình hóa thông tin ngữ nghĩa bao gồm:
    *   Truy xuất đa nhãn [207]
    *   Truy xuất ảnh không giám sát [219]
    *   Truy xuất ảnh có giám sát [102]
    *   Truy xuất ảnh bán giám sát [141]
*   **Băm nhận biết vị trí sâu (Deep position-aware hashing - DPAH)** dựa trên **độ tương tự ngữ nghĩa trong không gian Hamming** [89] và **Băm tái tạo ngữ nghĩa sâu (Deep semantic reconstruction hashing - DSRH)** dựa trên **ái lực ngữ nghĩa (semantic affinity)** [162] là các phương pháp gần đây cho truy xuất ngữ nghĩa.
## G. Truy xuất Ảnh Chi tiết (Fine-Grained Image Retrieval)

Để tăng **khả năng phân biệt (discriminative ability)** của các bộ mô tả được học sâu, nhiều nhà nghiên cứu đã sử dụng các **ràng buộc chi tiết (fine-grained constraints)** trong các mạng sâu.

Các công trình khác nhau đã kết hợp thuộc tính chi tiết bằng các phương pháp tiếp cận khác nhau, chẳng hạn như:
*   Nắm bắt các **độ tương tự giữa các lớp (inter-class)** và **trong nội bộ lớp (intra-class)** của hình ảnh bằng cách sử dụng một **mạng Siamese** [62]
*   Kết hợp thông tin **không gian-ngữ nghĩa (spatial-semantic)** dựa trên các **mô-đun chú ý (attention modules)** [137]
*   Sử dụng các **đặc trưng CNN có chọn lọc (selective CNN features)** [189]
*   **Xếp hạng chi tiết (Fine-grained ranking)** sử dụng **khoảng cách Hamming có trọng số (weighted Hamming distance)** [220]
*   Sử dụng **độ tương tự ngữ nghĩa đa cấp (multilevel semantic similarity)** giữa các **cặp ảnh đa nhãn (multi-label image pairs)** [211]
*   Sử dụng **mất mát entropy chéo từng đoạn (piecewise cross entropy loss)** [221]

## H. Truy xuất dựa trên Lượng tử hóa Bất đối xứng (Asymmetric Quantization based Retrieval)

*   Năm 2017, Wu et al. đã thực hiện **học độ tương tự bất đối xứng trực tuyến (online asymmetric similarity learning)** để bảo toàn độ tương tự giữa các **dữ liệu không đồng nhất (heterogeneous data)** [202].
*   Một phương pháp **băm sâu có giám sát bất đối xứng (asymmetric deep supervised hashing - ADSH)** được sử dụng bằng cách học **hàm băm sâu (deep hash function)** chỉ cho các **ảnh truy vấn (query images)**, trong khi các **mã băm (hash codes)** cho các **ảnh thư viện (gallery images)** được học trực tiếp [104].
*   Năm 2019, Yang et al. đã nghiên cứu **lượng tử hóa ngữ nghĩa sâu bất đối xứng (asymmetric deep semantic quantization - ADSQ)** sử dụng **ba mạng luồng (three stream networks)** để mô hình hóa dữ liệu không đồng nhất [222].
*   Một phương pháp **lượng tử hóa bất đối xứng sâu bảo toàn độ tương tự (similarity preserving deep asymmetric quantization - SPDAQ)** được đề xuất bằng cách khai thác **tập con hình ảnh (image subset)** và **thông tin nhãn (label information)** của tất cả các **mục cơ sở dữ liệu (database items)** [223].
*   Một phương pháp **băm bất đối xứng được hướng dẫn bởi đối thủ (adversary guided asymmetric hashing - AGAH)** được giới thiệu trong [160] với sự trợ giúp của **mô-đun chú ý đa nhãn (multi-label attention module)** được hướng dẫn bởi **học đối kháng (adversarial learning)** cho truy xuất ảnh đa phương thức.

## I. Tóm tắt (Summary)

Dựa trên sự tiến bộ trong truy xuất ảnh sử dụng các phương pháp học sâu cho các loại truy xuất khác nhau, sau đây là những điểm chính được rút ra từ phần này:

*   **Truy xuất đa phương thức (Cross-modal retrieval):** Các phương pháp tiếp cận học các đặc trưng **chung (joint)** cho nhiều phương thức bằng cách sử dụng các mạng khác nhau. Các phương pháp gần đây tận dụng **mạng đối kháng (adversarial network)** cho truy xuất đa phương thức. Nhận xét và xu hướng tương tự cũng được chứng kiến đối với truy xuất ảnh dựa trên phác thảo.

*   **Truy xuất đa nhãn và Thể hiện (Multi-label and Instance retrieval):** Các phương pháp tiếp cận này thường hữu ích khi có **nhiều hơn một loại kịch bản trực quan (more than one type of visual scenarios)** trong hình ảnh. Các phương pháp tiếp cận dựa trên học sâu có thể xử lý việc truy xuất như vậy bằng cách tạo điều kiện cho việc học đặc trưng thông qua các loại mạng khác nhau.

*   **Truy xuất Đối tượng (Object retrieval):** Việc **lựa chọn đặc trưng (feature selection)** dựa trên **mạng đề xuất vùng (region proposal network)** đã được sử dụng bởi các phương pháp học sâu hiện có.

*   **Truy xuất Ngữ nghĩa (Semantic retrieval):** Thông tin ngữ nghĩa của hình ảnh đã được sử dụng bởi các mạng khác nhau thông qua các đặc trưng trừu tượng để nâng cao truy xuất ảnh ngữ nghĩa. **Mạng dựa trên tái tạo (reconstruction based network)** phù hợp hơn cho **băm bảo toàn ngữ nghĩa (semantic preserving hashing)**.

*   **Truy xuất Ảnh Chi tiết (Fine-Grained retrieval):** Các mạng khác nhau dựa trên **lựa chọn (selection)** và **tổng hợp (aggregation)** đặc trưng đã được sử dụng.

*   **Băm Bất đối xứng (Asymmetric hashing):** Cũng đã cho thấy sự phù hợp của các mô hình học sâu bằng cách xử lý các ảnh truy vấn và ảnh thư viện với các mạng khác nhau.